{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d118b27-1bed-4f2d-b5c7-be07160c280f",
   "metadata": {},
   "source": [
    "# CNN nh·∫≠n di·ªán spam email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4486158-3da8-4d40-9bc2-2c3497463569",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl.metadata (4.6 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from keras>=3.10.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (10.4.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-win_amd64.whl (331.9 MB)\n",
      "   ---------------------------------------- 0.0/331.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/331.9 MB 16.8 MB/s eta 0:00:20\n",
      "    --------------------------------------- 6.6/331.9 MB 26.9 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 10.0/331.9 MB 18.3 MB/s eta 0:00:18\n",
      "   - -------------------------------------- 14.4/331.9 MB 20.6 MB/s eta 0:00:16\n",
      "   -- ------------------------------------- 24.1/331.9 MB 24.6 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 31.5/331.9 MB 26.6 MB/s eta 0:00:12\n",
      "   ---- ----------------------------------- 39.1/331.9 MB 27.9 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 46.9/331.9 MB 29.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 54.3/331.9 MB 30.1 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 62.4/331.9 MB 30.6 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 68.2/331.9 MB 30.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 76.0/331.9 MB 31.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 83.9/331.9 MB 31.5 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 91.8/331.9 MB 31.8 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 99.4/331.9 MB 32.2 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 106.7/331.9 MB 32.3 MB/s eta 0:00:07\n",
      "   ------------- ------------------------- 110.9/331.9 MB 32.5 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 120.6/331.9 MB 32.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 126.4/331.9 MB 31.9 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 134.7/331.9 MB 32.4 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 142.6/331.9 MB 32.5 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 149.9/331.9 MB 32.7 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 157.3/331.9 MB 32.8 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 162.8/331.9 MB 32.9 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 167.5/331.9 MB 32.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 175.1/331.9 MB 32.1 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 182.7/331.9 MB 32.2 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 190.3/331.9 MB 32.3 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 197.9/331.9 MB 32.4 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 205.3/331.9 MB 32.5 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 211.0/331.9 MB 32.6 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 216.8/331.9 MB 32.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 224.9/331.9 MB 32.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 232.5/331.9 MB 32.5 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 240.4/331.9 MB 32.6 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 248.0/331.9 MB 32.6 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 255.9/331.9 MB 32.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 263.5/331.9 MB 33.0 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 271.3/331.9 MB 33.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 279.4/331.9 MB 34.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 287.0/331.9 MB 34.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 294.6/331.9 MB 34.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 302.0/331.9 MB 34.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 308.8/331.9 MB 34.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 308.8/331.9 MB 34.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 319.3/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  326.6/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  331.9/331.9 MB 33.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 331.9/331.9 MB 22.2 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 35.8 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 7.9/26.4 MB 37.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.9/26.4 MB 36.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.5/26.4 MB 35.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 36.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 36.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 36.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 36.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 17.6 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.3-cp312-cp312-win_amd64.whl (208 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------  5.5/5.5 MB 37.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 30.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-win_amd64.whl (314 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt_einsum, ml_dtypes, google_pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google_pasta-0.2.0 keras-3.11.3 libclang-18.1.1 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "547e10c3-d8df-42c8-b286-f61d0c838969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-4.1.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (0.33.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pokig\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-4.1.1-py3-none-any.whl (503 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
      "   ---------------------------------------- 0.0/26.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.2/26.2 MB 19.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.1/26.2 MB 28.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.5/26.2 MB 26.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.2 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.2 MB 24.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.2 MB 24.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.2/26.2 MB 20.0 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: xxhash, pyarrow, multiprocess, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 16.1.0\n",
      "    Uninstalling pyarrow-16.1.0:\n",
      "      Successfully uninstalled pyarrow-16.1.0\n",
      "Successfully installed datasets-4.1.1 multiprocess-0.70.16 pyarrow-21.0.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5edd6b5-bf49-4941-93c0-1650bab112e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T·ªïng s·ªë m·∫´u: 5171\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pokig\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 29ms/step - accuracy: 0.8781 - loss: 0.2668 - val_accuracy: 0.9614 - val_loss: 0.0945\n",
      "Epoch 2/3\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.9857 - loss: 0.0533 - val_accuracy: 0.9865 - val_loss: 0.0495\n",
      "Epoch 3/3\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9969 - loss: 0.0158 - val_accuracy: 0.9874 - val_loss: 0.0354\n",
      "\n",
      "--- K·∫øt qu·∫£ D·ª± ƒëo√°n ---\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step\n",
      "'Win a free iPhone now!!!'\n",
      " -> SPAM üö® (98.84% Spam)\n",
      "'Meeting scheduled for tomorrow at 10am'\n",
      " -> HAM üëç (1.04% Spam)\n",
      "'Lowest price discount available, click this link'\n",
      " -> SPAM üö® (97.86% Spam)\n",
      "'Can we reschedule our call to next week?'\n",
      " -> HAM üëç (48.57% Spam)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# 1. Load dataset (SMS Spam Collection)\n",
    "# ==============================\n",
    "url = \"https://raw.githubusercontent.com/thehananbhat/spam-vs-ham/main/spam_ham_dataset.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Gi·ªØ l·∫°i 2 c·ªôt ch√≠nh\n",
    "df = df[['label', 'text']]\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "texts = df[\"text\"].tolist()\n",
    "labels = df[\"label\"].tolist()\n",
    "\n",
    "print(\"T·ªïng s·ªë m·∫´u:\", len(texts))\n",
    "\n",
    "# ==============================\n",
    "# 2. Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu\n",
    "# ==============================\n",
    "max_words = 10000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "y = np.array(labels)\n",
    "\n",
    "# Chia train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ==============================\n",
    "# 3. X√¢y d·ª±ng CNN ki·∫øn tr√∫c \n",
    "# ==============================\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),\n",
    "    Conv1D(64, 5, activation=\"relu\"),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(2, activation=\"softmax\")  # 2 l·ªõp: spam / ham\n",
    "])\n",
    "\n",
    "\n",
    "#=====================================================================\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# ==============================\n",
    "# 4. Train model\n",
    "# ==============================\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=3,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "# ==============================\n",
    "# 5. H√†m d·ª± ƒëo√°n email m·ªõi\n",
    "# ==============================\n",
    "def predict_spam_ham(texts):\n",
    "    seqs = tokenizer.texts_to_sequences(texts)\n",
    "    new_X = pad_sequences(seqs, maxlen=max_len, padding=\"post\", truncating=\"post\")\n",
    "    preds = model.predict(new_X)\n",
    "    results = []\n",
    "    for text, pred in zip(texts, preds):\n",
    "        # pred c√≥ 2 gi√° tr·ªã [p_ham, p_spam] v√¨ d√πng Dense(2, softmax)\n",
    "        p_ham, p_spam = pred\n",
    "        label = 'SPAM üö®' if p_spam >= 0.5 else 'HAM üëç'\n",
    "        results.append((text, label, f\"{p_spam*100:.2f}% Spam\"))\n",
    "    return results\n",
    "\n",
    "\n",
    "test_emails = [\n",
    "    \"Win a free iPhone now!!!\",\n",
    "    \"Meeting scheduled for tomorrow at 10am\",\n",
    "    \"Lowest price discount available, click this link\",\n",
    "    \"Can we reschedule our call to next week?\"\n",
    "]\n",
    "\n",
    "print(\"\\n--- K·∫øt qu·∫£ D·ª± ƒëo√°n ---\")\n",
    "for text, label, prob in predict_spam_ham(test_emails):\n",
    "    print(f\"'{text}'\\n -> {label} ({prob})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcf0f26-69e7-4769-8191-e82cd49a9d48",
   "metadata": {},
   "source": [
    "# CNN nh·∫≠n di·ªán ·∫£nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a936b277-5d23-4974-a972-cc0ad2092986",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ultralytics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# detect_people_yolo11n.py\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Demo ph√°t hi·ªán ng∆∞·ªùi trong ·∫£nh b·∫±ng YOLO11n\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# C·∫ßn c√†i: pip install ultralytics opencv-python matplotlib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ---------------------------------------------------\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'"
     ]
    }
   ],
   "source": [
    "# detect_people_yolo11n.py\n",
    "# ---------------------------------------------------\n",
    "# Demo ph√°t hi·ªán ng∆∞·ªùi trong ·∫£nh b·∫±ng YOLO11n\n",
    "# C·∫ßn c√†i: pip install ultralytics opencv-python matplotlib\n",
    "# ---------------------------------------------------\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "CONF_THRESH = 0.5   # Ng∆∞·ª°ng confidence (0 ‚Üí 1). L·ªõn h∆°n = √≠t false positive h∆°n\n",
    "MODEL_PATH = \"yolo11n.pt\"   # model YOLO (n: nano, nh·ªè g·ªçn)\n",
    "# ============================================\n",
    "\n",
    "def detect_people(image_path):\n",
    "    # 1. Load model YOLO11n\n",
    "    model = YOLO(MODEL_PATH)   # s·∫Ω t·ª± t·∫£i model l·∫ßn ƒë·∫ßu\n",
    "\n",
    "    # 2. Ch·∫°y d·ª± ƒëo√°n\n",
    "    results = model(image_path)\n",
    "\n",
    "    # 3. Hi·ªÉn th·ªã ·∫£nh v·ªõi bounding box\n",
    "    for r in results:\n",
    "        im_bgr = r.plot()  # ·∫£nh BGR c√≥ v·∫Ω box\n",
    "        im_rgb = cv2.cvtColor(im_bgr, cv2.COLOR_BGR2RGB)\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(im_rgb)\n",
    "        plt.title(\"K·∫øt qu·∫£ ph√°t hi·ªán b·∫±ng YOLO11n\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        # 4. L·ªçc ra ƒë·ªëi t∆∞·ª£ng class = \"person\"\n",
    "        people_boxes = []\n",
    "        names = r.names\n",
    "        for box in r.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            if names[cls_id] == \"person\" and conf >= CONF_THRESH:\n",
    "                xyxy = box.xyxy[0].tolist()  # [x1, y1, x2, y2]\n",
    "                people_boxes.append((xyxy, conf))\n",
    "\n",
    "        print(\"S·ªë ng∆∞·ªùi ph√°t hi·ªán:\", len(people_boxes))\n",
    "        for i, (bbox, conf) in enumerate(people_boxes, 1):\n",
    "            print(f\"Ng∆∞·ªùi {i}: BBox={bbox}, Conf={conf:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) < 2:\n",
    "        print(\"C√°ch ch·∫°y: python detect_people_yolo11n.py <D:/Downloads/vd1.jpg>\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    image_path = sys.argv[1]\n",
    "    detect_people(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca577e-0a83-46b2-8294-7409162f755b",
   "metadata": {},
   "source": [
    "# CNN ki·ªÉu d·ªØ li·ªáu s·ªë d·ª± ƒëo√°n nhi·ªát ƒë·ªô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abb0ae06-4021-43e5-b1a2-c087c1cf8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "# C√†i ƒë·∫∑t hi·ªÉn th·ªã numpy cho ƒë·∫πp\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "temps = 30 + np.random.randn(100)  # trung b√¨nh 30¬∞C, th√™m nhi·ªÖu\n",
    "print(\"Nhi·ªát ƒë·ªô 100 ng√†y:\", temps)\n",
    "\n",
    "X = temps.reshape(1, 100, 1)  # input shape (batch=1, length=100, feature=1)\n",
    "y = np.array([30 + np.random.randn()])  # gi·∫£ l·∫≠p gi√° tr·ªã ng√†y 101\n",
    "print(\"y:\" , y)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(100,1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X, y, epochs=20, verbose=0)\n",
    "\n",
    "print(\"Hu·∫•n luy·ªán xong.\")\n",
    "next_day_temp = model.predict(X)\n",
    "print(f\"D·ª± ƒëo√°n nhi·ªát ƒë·ªô ng√†y k·∫ø ti·∫øp: {next_day_temp[0][0]:.2f}¬∞C\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97250fc-f95c-46fe-86de-a229cc03d6a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
